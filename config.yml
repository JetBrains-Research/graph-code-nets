paths:
  data: "../data"
  vocab: "../vocab.txt"
model:
  configuration: "ggnn"
  base:
    hidden_dim: 128
    dropout_rate: 0.1
    num_edge_types: 24
  rnn:
    num_layers: 2
  ggnn:
    num_layers: 8
data:
  batch_size: 16 # In samples
  max_sequence_length: 128
  max_token_length: 8  # In terms of (BPE) sub-tokens.
training:
  max_steps: 100
  print_freq: 1000
  learning_rate: 0.0001
